{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imutils","metadata":{"id":"owWv5UOL11xD","execution":{"iopub.status.busy":"2021-08-04T12:51:31.739995Z","iopub.execute_input":"2021-08-04T12:51:31.740371Z","iopub.status.idle":"2021-08-04T12:51:41.542805Z","shell.execute_reply.started":"2021-08-04T12:51:31.740287Z","shell.execute_reply":"2021-08-04T12:51:41.541931Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting imutils\n  Downloading imutils-0.5.4.tar.gz (17 kB)\nBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=6672c8346514560c82ee8872408a65ba821875d421b31f3132935a5db50a75ce\n  Stored in directory: /root/.cache/pip/wheels/86/d7/0a/4923351ed1cec5d5e24c1eaf8905567b02a0343b24aa873df2\nSuccessfully built imutils\nInstalling collected packages: imutils\nSuccessfully installed imutils-0.5.4\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf \nimport cv2 \nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout\nfrom keras.models import Model, load_model\nfrom keras.callbacks import TensorBoard, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils import shuffle\nimport imutils","metadata":{"id":"1pcxYIH58NtV","execution":{"iopub.status.busy":"2021-08-04T12:51:42.909175Z","iopub.execute_input":"2021-08-04T12:51:42.909585Z","iopub.status.idle":"2021-08-04T12:51:47.602537Z","shell.execute_reply.started":"2021-08-04T12:51:42.909540Z","shell.execute_reply":"2021-08-04T12:51:47.601709Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"Classes=[\"Happy\",\"Sad\",\"Scared\",\"Surprised\"]\n\nmodel =Sequential([\n    Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    MaxPooling2D(2,2),\n\n    Conv2D(100, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n\n    Flatten(),\n    Dropout(0.5),\n    Dense(50, activation='relu'),\n    Dense(4, activation='softmax')\n])\n\nmodel.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"]) ","metadata":{"id":"YKMkTSqTC4JC","execution":{"iopub.status.busy":"2021-08-04T12:51:49.639852Z","iopub.execute_input":"2021-08-04T12:51:49.640180Z","iopub.status.idle":"2021-08-04T12:51:51.633348Z","shell.execute_reply.started":"2021-08-04T12:51:49.640151Z","shell.execute_reply":"2021-08-04T12:51:51.632513Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"Training_Directory=\"../input/face-emotions-6k-dataset/Training Dataset\"\n\ntrain_datagen = ImageDataGenerator(rescale=1.0/255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(Training_Directory,\n                                                    batch_size=10,\n                                                    target_size=(150, 150))","metadata":{"id":"WBg6bxVlC5uk","execution":{"iopub.status.busy":"2021-08-04T12:51:55.498682Z","iopub.execute_input":"2021-08-04T12:51:55.499041Z","iopub.status.idle":"2021-08-04T12:51:58.683476Z","shell.execute_reply.started":"2021-08-04T12:51:55.499011Z","shell.execute_reply":"2021-08-04T12:51:58.682513Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 6591 images belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(train_generator,epochs=15)","metadata":{"id":"kN1EXSWjEJcT","execution":{"iopub.status.busy":"2021-08-04T12:52:04.528793Z","iopub.execute_input":"2021-08-04T12:52:04.529114Z","iopub.status.idle":"2021-08-04T13:02:35.501107Z","shell.execute_reply.started":"2021-08-04T12:52:04.529085Z","shell.execute_reply":"2021-08-04T13:02:35.499827Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/15\n660/660 [==============================] - 60s 80ms/step - loss: 1.4235 - accuracy: 0.2845\nEpoch 2/15\n660/660 [==============================] - 40s 61ms/step - loss: 1.3706 - accuracy: 0.3122\nEpoch 3/15\n660/660 [==============================] - 43s 65ms/step - loss: 1.3738 - accuracy: 0.3048\nEpoch 4/15\n660/660 [==============================] - 40s 60ms/step - loss: 1.3677 - accuracy: 0.3164\nEpoch 5/15\n660/660 [==============================] - 42s 64ms/step - loss: 1.3602 - accuracy: 0.3370\nEpoch 6/15\n660/660 [==============================] - 41s 62ms/step - loss: 1.3619 - accuracy: 0.3388\nEpoch 7/15\n660/660 [==============================] - 40s 61ms/step - loss: 1.3391 - accuracy: 0.3566\nEpoch 8/15\n660/660 [==============================] - 41s 62ms/step - loss: 1.3383 - accuracy: 0.3509\nEpoch 9/15\n660/660 [==============================] - 39s 60ms/step - loss: 1.3265 - accuracy: 0.3500\nEpoch 10/15\n660/660 [==============================] - 41s 63ms/step - loss: 1.3260 - accuracy: 0.3553\nEpoch 11/15\n660/660 [==============================] - 40s 61ms/step - loss: 1.3309 - accuracy: 0.3618\nEpoch 12/15\n660/660 [==============================] - 41s 62ms/step - loss: 1.3113 - accuracy: 0.3709\nEpoch 13/15\n660/660 [==============================] - 39s 59ms/step - loss: 1.3078 - accuracy: 0.3748\nEpoch 14/15\n660/660 [==============================] - 41s 62ms/step - loss: 1.3003 - accuracy: 0.3907\nEpoch 15/15\n660/660 [==============================] - 41s 62ms/step - loss: 1.3047 - accuracy: 0.3817\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('emotion_detector.h5')","metadata":{"id":"2FmJPaxG_7vI","execution":{"iopub.status.busy":"2021-08-04T13:03:19.569571Z","iopub.execute_input":"2021-08-04T13:03:19.569912Z","iopub.status.idle":"2021-08-04T13:03:19.698923Z","shell.execute_reply.started":"2021-08-04T13:03:19.569879Z","shell.execute_reply":"2021-08-04T13:03:19.698036Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Testing the Model   trained_model.evaluate #For getting metrics on test data set","metadata":{"id":"3gvu6qvB2JRT"},"execution_count":null,"outputs":[]}]}